{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80555545",
   "metadata": {},
   "source": [
    "# Basic Profiling for Research Code\n",
    "\n",
    "Measuring code speed means determining how long a program or a portion of code\n",
    "takes to run, often using timers, benchmarks, or profiling tools. It helps you\n",
    "understand where your code spends time and whether certain parts are\n",
    "inefficient. However, it’s important to remember that you should only care\n",
    "about optimizing code performance when it actually wastes your time or the time\n",
    "of others. Constantly chasing small speedups for fun, especially without\n",
    "guidance from measurement, is usually unproductive. There are often more\n",
    "valuable ways to spend your effort than micro-optimizing code that already runs\n",
    "fast enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's take a look!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78f896",
   "metadata": {},
   "source": [
    "## Measuring Performance\n",
    "\n",
    "**What do we measure?**\n",
    "- *Wall time*: Real elapsed time; includes waiting, I/O, and scheduler delays.\n",
    "- *CPU time*: Time the CPU actually spent running your process (user + system).\n",
    "    - *User time*: Time running your code in user space (Python + C extensions)\n",
    "    - *System time*: Time the kernel spent doing work on your behalf (I/O, syscalls, memory management)\n",
    "\n",
    "**How do we measure it?**\n",
    "- *date/time clocks*: reflect the current calendar time; can jump forward or backwards due to timezone adjustments.\n",
    "  - please don’t use these to measure performance\n",
    "- *monotonic clocks*: measure elapsed time only, never goes backwards and unaffected by system clock adjustments.\n",
    "\n",
    "### Script-level Timing\n",
    "\n",
    "Tools:\n",
    "- `time` super simple and available nearly everywhere\n",
    "- `hyperfine` times repetitions & calculates statistics, can easily compare multiple scripts. Needs to be installed.\n",
    "\n",
    "```zsh\n",
    "# time sleep 1\n",
    "\n",
    "# hyperfine 'sleep .1'\n",
    "hyperfine 'sleep .2' 'sleep .1' 'sleep .3'\n",
    "```\n",
    "\n",
    "### Language-level Timing\n",
    "\n",
    "What if we want more granularity? Instead of timing entire programs, we can time subsets of programs.\n",
    "This is how we can begin to identify what portions of programs are \"slow\" and which are not.\n",
    "\n",
    "#### Block-level Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter # high performance monotonic clock\n",
    "from time import now                          # date clock\n",
    "from datetime import datetime; datetime.now() # date clock\n",
    "from time import sleep\n",
    "from random import Random\n",
    "\n",
    "rnd = Random(0)\n",
    "\n",
    "start = perf_counter()\n",
    "total = (\n",
    "    sum(rnd.randint(0, 100) for _ in range(10_000_000)) ** (1/2)\n",
    ")\n",
    "stop = perf_counter()\n",
    "print(f'{stop - start:.6f}s for our slow computation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e799f",
   "metadata": {},
   "source": [
    "We can turn this into a reusable context manager to time any arbitrary snippet of Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d07874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from contextlib import contextmanager\n",
    "from random import Random\n",
    "\n",
    "@contextmanager\n",
    "def timed(msg=''):\n",
    "    start = perf_counter()\n",
    "    stop = None\n",
    "    try:\n",
    "        yield lambda: stop - start\n",
    "    finally:\n",
    "        stop = perf_counter()\n",
    "        print(f'{msg: <24} {(stop - start):,.6f}s'.strip())\n",
    "\n",
    "rnd = Random(0)\n",
    "with timed('sqrt(sum(10M random integers))') as t:\n",
    "    total = (\n",
    "        sum(rnd.randint(0, 100) for _ in range(10_000_000)) ** (1/2)\n",
    "    )\n",
    "\n",
    "print(f'{t() = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020de01e",
   "metadata": {},
   "source": [
    "#### Function-level Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3144722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep, perf_counter\n",
    "from random import Random\n",
    "from functools import wraps\n",
    "\n",
    "def timed(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = perf_counter()\n",
    "        result = f(*args, **kwargs)\n",
    "        stop = perf_counter()\n",
    "        print(f'{stop - start:.6f}s')\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# @timed\n",
    "def func(n, rnd=Random(0)):\n",
    "    return sum(rnd.randint(0, 100) for _ in range(n)) ** (1/2)\n",
    "\n",
    "# timed(func, 10)\n",
    "# timed(func, 10_000)\n",
    "# timed(func, 10_000_000)\n",
    "\n",
    "func(10)\n",
    "func(10_000)\n",
    "func(10_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41d35f",
   "metadata": {},
   "source": [
    "This is great, but what if I don’t want to rewrite my program in order to time its\n",
    "subroutines/functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from sys import setprofile\n",
    "from time import perf_counter, sleep\n",
    "from inspect import signature\n",
    "\n",
    "def slow():\n",
    "    sleep(.5)\n",
    "    return True\n",
    "\n",
    "def fast():\n",
    "    sleep(.1)\n",
    "    return True\n",
    "\n",
    "@contextmanager\n",
    "def timer(*funcs):\n",
    "    towatch = {f.__code__: f.__qualname__ for f in funcs}\n",
    "    active = {}\n",
    "    def _profile(frame, event, arg):\n",
    "        if event == 'call' and frame.f_code in towatch:\n",
    "            active[frame.f_code] = perf_counter()\n",
    "        elif event == 'return':\n",
    "            try:\n",
    "                start = active.pop(frame.f_code)\n",
    "            except KeyError:\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"func {towatch[frame.f_code]!r} took {perf_counter() - start:6f}s\")\n",
    "    setprofile(_profile)\n",
    "\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        setprofile(None)\n",
    "\n",
    "\n",
    "def main():\n",
    "    slow()\n",
    "    slow()\n",
    "    fast()\n",
    "\n",
    "with timer(slow):\n",
    "    main()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668bf35",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295230b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import Profile\n",
    "from time import sleep\n",
    "\n",
    "def summation():\n",
    "    total = 0\n",
    "    for _ in range(10_000_000):\n",
    "        total += 1\n",
    "    return total\n",
    "\n",
    "def exponentiation():\n",
    "    start = 10_000_000\n",
    "    for _ in range(10_000_000):\n",
    "        start = pow(start, 0.5) # should be **= 0.5\n",
    "    return start\n",
    "\n",
    "with Profile() as pr:\n",
    "    summation()\n",
    "    exponentiation()\n",
    "\n",
    "pr.print_stats(sort=\"cumtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55356f77",
   "metadata": {},
   "source": [
    "You can even do this in a jupyter notebook!\n",
    "\n",
    "*timing*:\n",
    "    - prefix any line with `%timeit` to time a single line\n",
    "    - prefix any cell with `%%timeit` to time a single cell\n",
    "\n",
    "*profiling*:\n",
    "    - prefix any line with `%prun` to time a single line\n",
    "    - prefix any cell with `%%prun` to time a single cell\n",
    "    - jupyter line_profiler()\n",
    "\n",
    "## (In)Efficiently Loading Data from Lots of Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "from random import Random\n",
    "\n",
    "def date_range(start, stop, step=timedelta(days=1)):\n",
    "    while start <= stop:\n",
    "        yield start\n",
    "        start += step\n",
    "\n",
    "rnd = Random(0)\n",
    "data_dir = Path(\"data\", \"dates\")\n",
    "data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for dt in date_range(date(2000, 1, 1), date(2000, 12, 31)):\n",
    "    with open(data_dir / f\"{dt:%Y-%m-%d}.txt\", \"w\") as f:\n",
    "        for _ in range(100):\n",
    "            value = rnd.randint(0, 100)\n",
    "            f.write(f\"{value}\\n\")\n",
    "    print(f'wrote {f.name}!')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "find data/dates -name '*.txt' | xargs -n1 wc -l | sort -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d35fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, int64\n",
    "from pathlib import Path\n",
    "from numpy import append as np_append, loadtxt, concat\n",
    "from fileinput import FileInput\n",
    "\n",
    "data_dir = Path(\"data\", \"dates\")\n",
    "\n",
    "def a(): # I.\n",
    "    xs = array([], dtype=int64)\n",
    "    for path in data_dir.glob(\"*.txt\"):\n",
    "        with open(path, \"r\") as f:\n",
    "            for ln in f:\n",
    "                xs = np_append(xs, int(ln))\n",
    "    return xs\n",
    "\n",
    "def b(): # II.\n",
    "    xs = []\n",
    "    for path in data_dir.glob(\"*.txt\"):\n",
    "        values = loadtxt(path, dtype=int64)\n",
    "        xs.append(values)\n",
    "    return concat(xs, dtype=int64)\n",
    "\n",
    "def c(): # III.\n",
    "    with FileInput(files=data_dir.glob(\"*.txt\")) as f:\n",
    "        return loadtxt(f)\n",
    "\n",
    "\n",
    "from cProfile import Profile\n",
    "import pstats\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "\n",
    "# profile each function and collect results & profile stats\n",
    "results = {}\n",
    "for func in [a, b, c]:\n",
    "    with Profile() as pr:\n",
    "        res = func()\n",
    "\n",
    "    with redirect_stdout(StringIO()) as buffer:\n",
    "        pr.print_stats(\"cumtime\")\n",
    "    results[func] = (res, buffer.getvalue())\n",
    "\n",
    "for func, (_, perf) in results.items():\n",
    "    print(\n",
    "        f' Func {func.__qualname__!r} '.center(80, '='),\n",
    "        *perf.splitlines()[:1],\n",
    "        *perf.splitlines()[3:12],\n",
    "        sep='\\n'\n",
    "    )\n",
    "\n",
    "# verify results are accurate/comparable to one another\n",
    "from itertools import pairwise\n",
    "numeric_results = (res for res, _ in results.values())\n",
    "assert all((a == b).all() for a, b in pairwise(numeric_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2378f",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "Basic measurement tells you how long your code takes overall; profiling tells\n",
    "you which parts of the code are responsible for that time.\n",
    "\n",
    "Remember, your code is only slow if it begins to waste your time or the time of others.\n",
    "If you just need a script to run one time and one time only, it is okay if it takes a couple hours.\n",
    "\n",
    "| Aspect     | Basic Measurement                   | Profiling                                                   |\n",
    "| ---------- | ----------------------------------- | ----------------------------------------------------------- |\n",
    "| Goal       | How long or how much overall        | Detailed insight into performance distribution              |\n",
    "| Scope      | Entire program, single metric       | Function-by-function, line-by-line, or resource-specific    |\n",
    "| Tools      | `time`, `hyperfine`, `timeit`       | `cProfile`, `line_profiler`, `pyinstrument`, `setprofile`   |\n",
    "| Output     | Single number (seconds, CPU time)   | Detailed report: calls, time per call, percentage of total  |\n",
    "| Use Case   | Quick estimation, benchmarking      | Optimization, understanding bottlenecks, performance tuning |\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
